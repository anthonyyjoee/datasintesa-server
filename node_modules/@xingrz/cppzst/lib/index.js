"use strict";
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.decompressStream = exports.decompressStreamChunk = exports.TransformStreamDecompressor = exports.compressStream = exports.compressStreamChunk = exports.TransformStreamCompressor = exports.decompressSync = exports.compressSync = exports.decompress = exports.compress = void 0;
const stream_1 = require("stream");
const pond_1 = __importDefault(require("pond"));
const zstd_1 = __importDefault(require("./zstd"));
async function compress(input, params = {}) {
    if (!Buffer.isBuffer(input)) {
        throw new Error('Input is not a buffer.');
    }
    const stream = new TransformStreamCompressor(params);
    const pipeline = (0, pond_1.default)(stream);
    stream.end(input);
    return pipeline.spoon();
}
exports.compress = compress;
async function decompress(input, params = {}) {
    if (!Buffer.isBuffer(input)) {
        throw new Error('Input is not a buffer.');
    }
    const stream = new TransformStreamDecompressor(params);
    const pipeline = (0, pond_1.default)(stream);
    stream.end(input);
    return pipeline.spoon();
}
exports.decompress = decompress;
function compressSync(input, params = {}) {
    if (!Buffer.isBuffer(input)) {
        throw new Error('Input is not a buffer.');
    }
    const stream = new TransformStreamCompressor(params || {}, true);
    const chunks = [];
    let length = 0;
    stream.on('error', function (e) {
        throw e;
    });
    stream.on('data', function (c) {
        chunks.push(c);
        length += c.length;
    });
    stream.end(input);
    return Buffer.concat(chunks, length);
}
exports.compressSync = compressSync;
function decompressSync(input, params = {}) {
    if (!Buffer.isBuffer(input)) {
        throw new Error('Input is not a buffer.');
    }
    const stream = new TransformStreamDecompressor(params || {}, true);
    const chunks = [];
    let length = 0;
    stream.on('error', function (e) {
        throw e;
    });
    stream.on('data', function (c) {
        chunks.push(c);
        length += c.length;
    });
    stream.end(input);
    return Buffer.concat(chunks, length);
}
exports.decompressSync = decompressSync;
class TransformStreamCompressor extends stream_1.Transform {
    constructor(params = {}, sync = false) {
        super();
        this.compressor = new zstd_1.default.StreamCompressor(params || {});
        this.sync = sync;
        const blockSize = this.compressor.getBlockSize();
        this.status = {
            blockSize: blockSize,
            remaining: blockSize
        };
    }
    _transform(chunk, encoding, next) {
        compressStreamChunk(this, chunk, this.compressor, this.status, this.sync, next);
    }
    _flush(done) {
        this.compressor.compress(true, (err, output) => {
            if (err) {
                return done(err);
            }
            if (output) {
                for (let i = 0; i < output.length; i++) {
                    this.push(output[i]);
                }
            }
            return done();
        }, !this.sync);
    }
}
exports.TransformStreamCompressor = TransformStreamCompressor;
// We need to fill the blockSize for better compression results
function compressStreamChunk(stream, chunk, compressor, status, sync, done) {
    const length = chunk.length;
    if (length > status.remaining) {
        const slicedChunk = chunk.slice(0, status.remaining);
        chunk = chunk.slice(status.remaining);
        status.remaining = status.blockSize;
        compressor.copy(slicedChunk);
        compressor.compress(false, function (err, output) {
            if (err) {
                return done(err);
            }
            if (output) {
                for (let i = 0; i < output.length; i++) {
                    stream.push(output[i]);
                }
            }
            return compressStreamChunk(stream, chunk, compressor, status, sync, done);
        }, !sync);
    }
    else if (length <= status.remaining) {
        status.remaining -= length;
        compressor.copy(chunk);
        return done();
    }
}
exports.compressStreamChunk = compressStreamChunk;
function compressStream(params = {}) {
    return new TransformStreamCompressor(params);
}
exports.compressStream = compressStream;
class TransformStreamDecompressor extends stream_1.Transform {
    constructor(params = {}, sync = false) {
        super();
        this.decompressor = new zstd_1.default.StreamDecompressor(params || {});
        this.sync = sync || false;
        const blockSize = this.decompressor.getBlockSize();
        this.status = {
            blockSize: blockSize,
            remaining: blockSize
        };
    }
    _transform(chunk, encoding, next) {
        decompressStreamChunk(this, chunk, this.decompressor, this.status, this.sync, next);
    }
    _flush(done) {
        this.decompressor.decompress((err, output) => {
            if (err) {
                return done(err);
            }
            if (output) {
                for (let i = 0; i < output.length; i++) {
                    this.push(output[i]);
                }
            }
            return done();
        }, !this.sync);
    }
}
exports.TransformStreamDecompressor = TransformStreamDecompressor;
// We need to fill the blockSize for better compression results
function decompressStreamChunk(stream, chunk, decompressor, status, sync, done) {
    const length = chunk.length;
    if (length > status.remaining) {
        const slicedChunk = chunk.slice(0, status.remaining);
        chunk = chunk.slice(status.remaining);
        status.remaining = status.blockSize;
        decompressor.copy(slicedChunk);
        decompressor.decompress(function (err, output) {
            if (err) {
                return done(err);
            }
            if (output) {
                for (let i = 0; i < output.length; i++) {
                    stream.push(output[i]);
                }
            }
            return decompressStreamChunk(stream, chunk, decompressor, status, sync, done);
        }, !sync);
    }
    else if (length <= status.remaining) {
        status.remaining -= length;
        decompressor.copy(chunk);
        return done();
    }
}
exports.decompressStreamChunk = decompressStreamChunk;
function decompressStream(params = {}) {
    return new TransformStreamDecompressor(params);
}
exports.decompressStream = decompressStream;
;
